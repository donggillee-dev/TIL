# Operating System

`하드웨어를 관리하며 하드웨어와 응용 프로그램 사이에서 인터페이스 역할을 하여 시스템의 동작을 제어하는 시스템 소프트웨어`

- [프로세스](#프로세스)

- [멀티 프로세스](#멀티-프로세스)

- [스레드](#스레드)

- [멀티 스레드](#멀티-스레드)

- [멀티 스레드 vs 멀티 프로세스](#멀티-스레드-vs-멀티-프로세스)

- [동기화 문제](#동기화-문제)

- [동기 vs 비동기 & Blocking vs Non-Blocking](#동기-vs-비동기-&-blocking-vs-non-blocking)

- [인터럽트](#인터럽트)

- [PCB](#pcb)

- [Context Switching](#context-switching)

- [IPC](#ipc)

- [시스템 콜](#시스템-콜)

- [데드락](#데드락)

- [CPU Scheduling](#cpu-cheduling)

- [페이징과 세그멘테이션](#페이징과-세그멘테이션)

- [메모리](#메모리)







## 프로세스

> 실행 중인 프로그램을 의미하며 메모리에 적재되어 CPU의 할당을 받으며 스케줄링의 대상이 되는 것

- 메모리에 올라와 실행되고 있는 프로그램(*.exe)의 인스턴스

- HDD에 존재하는 프로그램을 실행시키면 이를 위해 메모리 할당이 이뤄지고 할당된 메모리 영역에 바이너리 코드가 올라간다. 이때부터 프로세스라고 칭한다

- ##### OS로부터 할당받는 자원

  - CPU 시간
  - 운영되기 위해 필요한 주소 공간
  - Code, Data, Stack, Heap을 위한 독립된 메모리 공간

- ##### 메모리 구조

  - Code 영역 : 프로그램을 실행시키는 실행 파일 내의 명령어 할당
  - Data 영역 : 전역, static 변수 할당(+ 초기화 안된거는 bss, 초기화 된건 data)
  - Stack 영역 : 지역변수, 매개변수, 리턴값 등을 위한 영역
  - Heap 영역 : 동적 할당을 위한 영역
  - Stack은 위에서 아래로, Heap은 아래에서 위로

- ##### 특징

  - 프로세스는 각각 독립된 영역(Code, Data, Stack, Heap)을 OS로부터 할당받는다

    ![](https://user-images.githubusercontent.com/55429912/120060193-47a94a80-c091-11eb-8dd4-7e49dca2302f.png)

  - 프로세스상 최소 1개의 스레드 보유(메인 스레드)

  - 각 프로세스는 별도의 주소 공간에서 독립되어 실행된다. 그러므로 서로의 자원에 접근하기 위해서는 IPC(Inter-process communication, 프로세스간 통신)을 사용해야한다



## 멀티 프로세스

> 두개 이상의 프로세서(CPU)가 하나 이상의 작업을 동시에 처리하는 것처럼 보이는 것(병렬 처리)

**장점**

- 안전성
  - 메모리 침범 문제를 OS 차원에서 해결
  - 여러 개의 프로세서에 분산 시, 한 프로세스가 정지되더라도 시스템은 정지되지 않고 전보다 처리 속도만 느려짐

**단점**

- 작업량이 늘어날 수록 오버헤드 발생, Context Switching으로 인한 성능 저하

  > 오버헤드 : 어떠한 작업을 처리하는데 드는 간접적인 처리 시간, 메모리



## 스레드

> 프로세스 내에서 수행되는 여러 흐름의 단위 (프로세스의 실행 단위, a.k.a light-weight process)

- ##### 특징

  - 스레드는 프로세스 내의 Code, Data, Heap 영역은 서로 공유하되, Stack만 각각 별도로 할당 받는다

    ![](https://camo.githubusercontent.com/3dc4ad61f03160c310a855a4bd68a9f2a2c9a4c7/68747470733a2f2f74312e6461756d63646e2e6e65742f6366696c652f746973746f72792f393938383931343635433637433330363036)

  - 또한 스레드는 스레드 ID, PC(실행할 명령문 주소값), 레지스터 집합, 스택으로 구성됨

  - 한 스레드가 프로세스 자원 변경시, 다른 이웃 스레드(sibling thread)도 변경값 즉시 확인 가능

- ##### 장점

  - 메모리 공유로 인해 시스템 자원 소모 감소
  - 응답시간 단축
  - Context Switching에 대한 오버헤드가 줄어듬(Stack만 switching하면 되기 때문)

- ##### 단점

  - 자원 동기화에 신경써야한다.
    

- ##### 프로세스와의 차이점

  - 프로세스는 자신만의 고유 공간 존재, 다른 프로세스와의 통신은 IPC를 통해서
  - 스레드는 다른 스레드와 자원을 공유한다



- ##### 스택을 독립적으로 할당하는 이유

  - 스택은 매개변수, 지역변수, 리턴 주소 등을 저장하기 위한 메모리 공간. 즉, 독립적인 함수 호출이 가능하다는 것이며 독립적인 실행 흐름을 가진다는 것
  - 따라서 스레드의 정의에 따라 독립적인 실행 흐름을 가지기 위한 최소 조건으로 스택은 분리

  

- ##### PC Register를 스레드별로 독립적이게 할당하는 이유

  - PC 값은 명령어가 어디까지 처리 되었는지 그 주소값을 가리킨다.
  - 스레드는 CPU를 할당받았다가 다시 선점당하기 때문에 그 실행 위치를 저장할 독립적인 공간 필요
    

## 멀티 스레드

> 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 병렬처리 하는 것

스레드들이 공유 메모리(Code, Data, Heap)을 통해 다수의 작업을 동시에 처리하도록 함

장점 : 독립적인 프로세스 대비 공유 메모리만큼의 시간, 자원 손실 감소, 전역 변수, 정적 변수에 대한 공유 가능

단점 : 안정성 문제. 하나의 스레드가 공유 메모리 공간의 Data를 망가뜨리면 모든 스레드 동작 불능



## 멀티 스레드 vs 멀티 프로세스

> 시스템에 따라 적합/부적합으로 나뉘며 장단점이 극명하다

- ##### 멀티 스레드?

  - 장점
    - 멀티 스레드는 멀티 프로세스에 비해 적은 공간을 차지
    - context switching이 빠르다 => Stack만 처리하기 때문
    - IPC가 아닌 스레드간 메모리 공유로 인해 응답, 처리 속도 향상
  - 단점
    - 하지만, 공용 공간으로 인해 안정성 문제와 자원 동기화 문제에 대한 임계 영역 기법 처리 필요

- ##### 멀티 프로세스?

  - 장점
    - 하나의 프로세스가 죽어도 독립적이기에 다른 프로세스에 영향 x
  - 단점
    - 하지만, 멀티 스레드보다 많은 자원을 차지하는 단점이 존재
    - 프로세스 간의 context switching시에 캐시 메모리에 대한 데이터까지 초기화 되므로 오버헤드 커짐
    - IPC를 통해 통신해야기에 처리 비용 및 응답 시간 더 오래 걸림

둘 다 동시에 여러 작업을 처리한다는 점에서 목표는 같지만 시스템에 따라 다르게 적용



## 임계 영역(Critical Section)

> 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 영역에 대해 접근하는 코드의 일부



**임계 영역 문제?**

`프로세스들이 임계 영역에 동시 접근 시 발생하는 동기화 문제`



#### **임계 영역 문제를 처리하기 위한 조건**

1. ##### 상호 배제(Mutual Exclusion)

   - 하나의 프로세스가 임계 영역에 있다면 다른 프로세스 출입 불가

2. ##### 진행(Progress)

   - 임계 영역에 존재하는 프로세스가 없을 시 동시에 임계 영역에 접근하려는 프로세스가 여럿일 시, 그 순서를 적절히 결정해주어야 한다

3. ##### 한정된 대기(Bounded Waiting)

   - 임계 영역에 접근하기 위해 대기하는 프로세스의 Starvation을 방지하기 위해 한번 임계영역에 들어간 프로세스는 다음 번 임계 영역에 들어갈 때 제한을 주어야 한다



## Thread-Safe

> 멀티스레드 환경에서 여러 스레드가 동시에 공유 자원 접근 시, 의도한 대로 동작하게끔 하는 것



- Mutual Exclusion(상호 배제)
  - Thread-safe하기 위해서는 공유 자원에 접근하는 임계영역을 동기화 기법으로 제어(ex : Semaphore, Mutex)
- Re-entrancy
  - 어떤 함수가 스레드에 호출되어 실행중일때, 다른 스레드가 그 함수를 호출하더라도 그 결과가 각각에게 올바르게 주어져야 한다.
- Thread-safe storage
  - 공유 자원에 대한 사용을 최대한 줄이고 스레드에서만 접근 가능한 저장소를 통해 동시 접근을 방지한다.
- Atomic Operations
  - 데이터 변경시 Atomic하게 데이터에 접근하도록



## 동기화 문제

> 한정적인 자원에 여러 스레드가 동시 접근하는 문제 존재
>
> 이를 방지하기 위해 **여러 스레드에서 하나의 자원에 대한 처리 권한 및 순서를 조정**하는 기법



#### 스레드 동기화

1. ##### **실행 순서**의 동기화

   - 스레드의 실행 순서를 정해서 한번에 하나의 스레드만 작업하도록 하는 것

2. ##### **메모리 접근**에 대한 동기화

   - 메모리 관점에서의 동시 접근을 막는 것
   - 실행 순서가 아닌 한 순간에 하나의 스레드만 임계 영역에 접근하도록 하는 것



#### 동기화 기법

- ##### **유저 모드**의 동기화

  - 커널의 힘을 빌리지 않는 동기화 기법(커널 코드 실행 x)
  - **성능상 이점**이 존재, **기능상의 제한점** 존재
  - 임계 구역 기반의 동기화, 인터락 함수 기반의 동기화

##### **커널 모드**의 동기화

- 커널에서 제공하는 동기화 기능 사용
- 커널 모드로의 변경이 필요. 즉, 성능 저하, 하지만 다양한 기능 활용 가능
- 세마포어, 뮤텍스, 모니터 등등



#### 유저 모드 동기화

##### 1. 임계 구역 기반 동기화

- 열쇠를 얻은 프로세스만 임계 구역에 들어갈 수 있다. 즉, 한번에 하나의 스레드만 접근 가능
- 임계 구역 진입을 위해 **Critical Section Object**를 얻는다
- 다른 스레드가 열쇠를 가지고 있을 시에는 반환 전까지 블로킹된다. 열쇠가 반환되면 블로킹 상태에서 빠져나와 열쇠를 가지고 임계 구역에 진입

##### 2. 인터락 함수 기반 동기화

- 함수 내부적으로 한 순간에 하나의 스레드에 의해서만 임계 구역 실행되도록 동기화
- 임계 구역 기반의 동기화도 내부적으로 인터락 함수 기반으로 구현된다
- 유저 모드 기반이라 속도가 빠르다



#### 커널 모드 동기화

##### 1. 세마포어 (Semaphore)

- 공유된 자원의 데이터를 여러 프로세스, 스레드가 접근하는 것을 막는다

- 동시에 접근할 수 있는 '허용 가능 갯수'를 갖고 있는 Counter

  - ex) 화장실에 비유해서 화장실 칸이 4개고 키가 4개(Counter) 라면 최대 4명까지 대기없이 사용 가능

- Counter의 개수에 따라 분류됨

  - 1개 : Binary Semaphore => 사실상 Mutex
  - 2개 이상 : Counting Semaphore

- 세마포어는 소유 불가

  - 하지만 세마포어를 소유하지 않은 다른 스레드가 세마포어 해제 가능 => 커널 단에서 관리하기 때문

  - 즉, 서로 다른 프로세스에서 접근이 가능하다

    

##### 2. 뮤텍스 (Mutex)

- 공유된 자원의 데이터를 여러 프로세스, 스레드가 접근하는 것을 막는다

- 임계 영역에 대한 서로 다른 스레드들의 Running Time이 겹치지 않게하기 위함

- 뮤텍스 객체를 동시에 두 스레드에서 사용 불가

- 일종의 Lock 메커니즘으로 공유 자원에 대한 locking과 unlocking을 사용

- Lock에 대한 소유권이 있으며 lock을 가지고 있을 경우에만 공유 자원에 접근 가능, Lock을 가진 사람만 반납 가능

- 무조건 1개의 열쇠만 가질 수 있음

  

##### 3. 모니터 (Monitor)

- Mutex(Lock)과 Condition Variables를 가지고 있는 Synchronization 매커니즘
- 임계 구역에 하나의 스레드만 진입 가능



| 모드 |            이름             |           사용            | 설명                                                         |
| :--: | :-------------------------: | :-----------------------: | :----------------------------------------------------------- |
| 유저 |    임계 영역 기반 동기화    | 메모리 접근 동기화에 사용 | Critical Section Object(자료형 CRITICAL_SECTION인 객체)를 만들고 초기화 |
| 유저 |   인터락 함수 기반 동기화   | 메모리 접근 동기화에 사용 | 함수 내부적으로 한 순간에 하나의 쓰레드에 의해 실행되도록 동기화 |
| 커널 |     뮤텍스 기반 동기화      | 메모리 접근 동기화에 사용 | 키의 취득과 반납이 이루어짐(키 하나, 즉 동기화 대상 하나)    |
| 커널 |    세마포어 기반 동기화     | 메모리 접근 동기화에 사용 | 카운트를 통해 이루어짐(키 여러개, 즉 동기화 대상 여러개)     |
| 커널 | 이름있는 뮤텍스 기반 동기화 | 프로세스간 동기화에 사용  | 프로세스간에 동기화를 하기 위해 뮤텍스를 동기화 해야하는데 커널 오브젝트는 프로세스에 독립적이므로 뮤텍스에 이름을 붙여서 접근 |
| 커널 |     이벤트 기반 동기화      |  실행순서 동기화에 사용   |                                                              |



## Mutex & Semaphore & Monitor

#### 1. 뮤텍스와 모니터의 차이

- 뮤텍스는 다른 프로세스, 스레드 간 동기화를 위해 사용
- 모니터는 하나의 프로세스내에서 다른 스레드간의 동기화를 위해 사용
- 뮤텍스는 커널에 의해 제공된다 => 무겁고 느림
- 모니터는 라이브러리, 프레임워크에 자체에서 제공 => 가볍고 빠름



#### 2. 세마포어와 모니터의 차이

- 세마포어는 카운터라는 변수 값을 상호 배제 목적으로 매번 값의 수정 및 재지정이 일어난다
- 모니터는 이러한 일들이 캡슐화되어있어 synchronized, wait(), nofify()를 이용해 간단히 가능



#### 3. 뮤텍스와 세마포어의 차이

- 세마포어는 뮤텍스가 될 수 있지만, 뮤텍스는 세마포어가 될 수 없다
- 세마포어는 소유 불가능, 뮤텍스는 소유 가능 그리고 소유주가 책임을 진다
  - 즉 뮤텍스의 경우에는 OS가 trace하기에 키를 가진채 오류가 발생해 반납 안하고 종료되면, OS가 가지고와서 다음 녀석에서 준다
- 뮤텍스의 경우, 뮤텍스 소유주가 뮤텍스를 해제할 수 있지만, 세마포어는 소유자가 아니더라도 해제 가능
  

#### Atomic Operation

> 실행 중에 중단하지 않는 순차적인 기계어 명령

세마포어 실행은 Atomic Operation이어야함

Atomic하지 않은 경우 → 명령어 도중 인터럽트 발생 → Context Switching이 발생 가능 → 동시 접근 허용 → 공유 자원 충돌 발생



## 동기 vs 비동기 & Blocking vs Non-Blocking

#### 동기?

> 어떤 작업을 요청했을때 그 작업의 결과값을 계속해서 신경씀

- 작업 요청을 했을 시에 요청의 결과값(return)을 직접 받는다
- 요청한 결과값이 return값과 동일
- 호출한 함수가 작업 완료를 신경 쓴다

- 요청한 작업만 처리하면 되기 때문에 전체적인 수행 속도를 빠를 수 있음
- 한 작업에 대한 처리 시간이 길어질 경우 전체 응답 시간이 지연될 수 있음



#### 비동기?

> 어떤 작업을 요청해놓고 그 작업의 결과에 대해 신경쓰지 않고 다른일 수행

- 작업 요청을 해놓고 요청의 결과값(return)을 간접적으로 받는 것
- 요청의 결과값이 return값과 다를 수 있음
- 콜백을 통한 처리가 대표적인 비동길 처리
  - callback을 호출한 함수는 callback의 결과값을 신경쓰지 않음
  - callback함수가 작업의 완료를 신경쓴다.
- 작업이 끝날 때 따로 이벤트를 감지하고 결과를 받아 그에 따른 추가 작업을 해줘야 하기에 비교적 느릴 수 있음
- I/O 작업이 잦고 빠른 응답속도를 요구하는 프로그램에 적합



#### Blocking

- 시스템 콜이 끝날때까지 프로그램은 대기하고 시스템콜이 완료되면 그때 제어권 넘김
- Wait Queue에 들어간다



#### Non-Blocking

- 시스템 콜이 끝나지 않아도 대기하지 않고 제어권을 반환
- Wait Queue에 들어가지 않는다



#### Blocking vs Non-Blocking

- Blocking : 서브 루틴이 제어권을 바로 반환하지 않기에 본래 루틴 수행 불가
- Non-Blocking : 서브 루틴이 바로 호출되자마자 제어권을 반환하기에 본래 루틴 수행 가능



#### Sync vs Async

- Sync : 결과물의 반환 시점이 return과 동일
- Async : 결과물의 반환 시점이 return 시점과 동일하지 않다. 나중에 완료되면 그때 가져올 수 있음( 콜백처리 )



#### Async vs Non-Blocking

- Async : 요청의 처리 완료와 상관없이 응답
- Non-Blocking : 요청에 처리할 수 있으면 바로 응답, 아니면 Error 반환



#### Sync vs Blocking

- Sync : 시스템 콜의 return을 기다리는 동안 Wait Queue에 들어갈 수도 안들어갈 수도
- Blocking : 시스템 콜의 return을 기다리는 동안 Wait Queue에 들어가있는다.



## 인터럽트

> 프로그램 실행 도중 예기치 못한 상황 발생시 실행 중인 작업을 중지하고 우선 처리가 필요함을 CPU에게 알리는 행위



#### **Why?**

`입출력 연산이 CPU 명령 수행속도보다 현저히 느리기 때문`



#### **하드웨어 인터럽트**

- 외/내부 인터럽트가 존재하며 CPU의 하드웨어 신호에 의해 발생

- 외부 인터럽트

  - 입출력, 타이밍, 전원 등 외부적 요인으로 발생

- 내부 인터럽트

  - Trap이라고 불리며, 잘못된 명령이나 데이터 사용시 발생

    > 0으로 나누기, 오버플러우, Exception

  

#### **소프트웨어 인터럽트**

- 프로그램 처리 중 명령 요청에 의해 발생 하는 것 (SVC 인터럽트)
  - 사용자가 프로그램을 실행시킬 때 발생



#### **인터럽트 처리 과정**

![](https://user-images.githubusercontent.com/55429912/120112394-94377780-c1b0-11eb-8277-e390ea0cc243.png)

- 인터럽트 서비스 루틴 수행 후 다시 중지 지점으로 돌아오기 위해 상태 레지스터와 PC 등을 스택에 저장한다.

- 만약 인터럽트 기능이 없다면 컨트롤러는 특정 일을 처리할 시기를 알기 위해 계속 체크해야함(폴링 방식)
  - 폴링 방식은 원래 하던 일에 집중할 수 없는 단점이 존재



#### **CPU 명령어의 종류**

1. 일반 명령
   - 메모리에서 자료 읽고, CPU에서 계산을 하는 등의 명령
   - 모든 프로그램이 수행 가능한 명령
2. 특권 명령
   - 입출력, 타이머 등의 장치를 접근하는 명령
   - 보안이 필요한 명령으로 OS만이 수행 가능



#### **관련 용어**

- 인터럽트 핸들러(인터럽트 서비스 루틴) : 실제 인터럽트를 처리하기 위해 짜여진 루틴. OS 코드 영역에는 이미 인터럽트 별로 수행되어야 하는 루틴들이 프로그램 되어있음
- 인터럽트 벡터 : 인터럽트 발생 시 처리해야할 인터럽트 핸들러의 주소를 인터럽트 별로 가지고 있는 테이블



## PCB

> Process Control Block이라고도 하며, 프로세스 메타데이터들을 저장해 놓는 곳

- 한 PCB안에는 한 프로세스의 정보가 담김
- 커널의 데이터 영역에 존재
- 인터럽트 발생시에 프로세스의 메타데이터를 저장



#### **PCB 필요한 이유?**

- 다른 작업을 수행하고 돌아와서 다시 수행할 프로세스의 상태값을 저장하기 위해



#### **PCB 관리 방식**

- Linked List방식으로 관리
- PCB List Head에 PCB들이 생성될 때마다 추가되게 된다. 주소값으로 연결이 이루어져있기에 삽입, 삭제가 용이
- 즉, 프로세스가 생성되면 해당 PCB 생성되고 프로세스가 완료되면 해당 PCB삭제



## Context Switching

> 현재 진행하고 있는 작업(프로세스, 스레드)의 상태를 저장하고 다음 진행할 작업의 상태 값을 읽어 적용하는 과정

![](https://user-images.githubusercontent.com/55429912/120107634-c6d77500-c19c-11eb-9f74-3bb2e75b4b86.png)

#### Why?

- 한번에 하나의 Task밖에 처리 못한다면?
  - 해당 Task가 끝날때까지 다음 Task기다려야함
  - 또한 반응속도가 느리고 사용하기 불편
- 동시에 처리하는 것처럼 사용하기 위해서는?
  - 멀티태스킹을 통해 빠른 반응속도 추구
  - 이를 통해 사람들 눈에는 동시에 처리하는 것처럼 보임
  - 이를 위해서는 Cpu가 Task를 바꿔가며 실행하기 위해 Context Switching 필요함



#### Context Switching 과정

1. Task에 대한 정보는 레지스터에 저장, PCB로 관리 된다

2. 현재 실행하고 있는 Task의 PCB를 저장
3. 다음 실행할 Task의 PCB정보를 읽어 레지스터에 적재, CPU가 해당 Task의 이전에 진행하던 부분을 이어서 진행



#### Context Switching 비용

- Cache 초기화
- Memory Mapping 초기화
- Process > Thread
  - 스레드의 Context Switching 대상은 Stack뿐 나머지는 프로세스 내에서 공유하기 때문



## IPC

> 프로세스간에 통신(Inter-Process Communication)

![](https://user-images.githubusercontent.com/55429912/120153217-69d5d080-c229-11eb-93ec-2e001d9e48ca.png)

- 리눅스의 커널구조이다
- 프로세스들은 모두 독립된 메모리 영역을 할당받고 독립적으로 실행됨
- 독립된 구조인 만큼 별도의 설비가 없어 직접적인 통신이 어려움



#### IPC 종류

| 이름             | 사용                                                         | 특징                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 익명 PIPE        | 통신할 프로세스를 명확하게 아는 경우<br />(부모 - 자식 프로세스) | - 한쪽 방향으로만 통신 가능한 Half-Duplex(반이중)통신<br />- Full-Duplex(전이중)통신을 위해서는 2개의 PIPE가 필요 |
| Named PIPE(FIFO) | 전혀 모르는 프로세스들 사이에서 통신                         | - 프로세스간의 통신을 위해 이름이 있는 파일을 사용<br />- mkfifo를 통해 PIPE생성, 생성 성공시 명명된 파일이 생성됨<br />- Full-Duplex(전이중)통신을 위해서는 2개의 PIPE가 필요 |
| Message Queue    | 메모리 공간으로 사용                                         | - 메시지 큐에 사용할 데이터를 라벨링함으로써 여러 개의 프로세스가 데이터를 쉽게 다룰 수 있음<br />- 커널에서 관리 |
| Shared Memory    | 메모리를 공유                                                | - 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용<br />- IPC 방법들 중에서 가장 빠르게 작동(중재자가 없기때문) |
| Memory Map       | 메모리를 공유                                                | - 오픈된 파일에 한해서 메모리에 매핑시켜 공유(Shared Memory와의 차이점)<br />- 메모리의 내용을 파일로 남길 수 있음 |
| Semaphore        | 프로세스간 데이터를 동기화 및 보호                           | - Busy wait 상태에 놓이지 않음<br />- 커널에서 관리되기에 다른 프로세스에서 접근 가능 |
| Socket           | 물리적으로 떨어져 있는 컴퓨터간의 통신                       | - 네트워크 통신에 사용하는 기술을 그대로 사용<br />- 규모가 클 경우 효율적 |



#### 커널?

> 메모리에 상주하는 OS의 일부

- 운영체제 자체도 SW로 메모리에 올라가야한다
- OS는 큰 프로그램이기에 전체가 올라가면 공간 낭비 심함 그래서 일부만



## 시스템 콜

운영체제의 두가지 Operation

운영체제는 하드웨어적인 보안을 유지하기 위해 기본적으로 두가지 Operation을 지원

1. Kernal Mode(Mode Bit = 0) : OS가 CPU의 제어권을 가지고 명령을 수행하는 모드로 일반 명령, 특권 명령 모두 사용 가능
2. User Mode(Mode Bit = 1) : 일반 사용자 프로그램이 CPU제어권을 가지고 명령을 수행하는 모드이기에 일반 명령만 가능



#### 시스템 콜 수행

![](https://user-images.githubusercontent.com/55429912/120147817-3cd1ef80-c222-11eb-8392-7a5acfa6ea29.png)

1. CPU가 인터럽트 라인 세팅 여부 검사

2. 인터럽트 발생 감지 -> 현재 수행중인 사용자 프로그램 중지, CPU 제어권을 OS에게 양도(kernal mode)

3. Mode bit가 1 -> 0으로 변경되어 특권 명령 수행 가능

   > 시스템 콜을 커널 영역의 기능을 사용자 모드에서 가능하게 함



#### fork(), exec(), wait()

- fork, exec은 새로운 process 생성과 연관이 있다

  - exec의 경우 자식 부모 프로세스의 메모리에 자식 프로세스의 코드를 덮는다.

- wait는 부모 프로세스가 만든 자식 프로세스가 끝날 때까지 기다리는 명령

  > 부모의 fork() 값 => 자식의 pid
  >
  > 자식의 fork() 값 => 0



## 데드락

> 두개 이상의 작업이 자원을 소유한채 상대방이 점유한 자원을 원하며 아무것도 완료되지 못하는 상태. 각자 원하는 자원을 얻지 못해 다음 처리를 하지 못하는 상태이다.



#### 교착상태 조건

1. 상호배제(Mutual Exclusion)
   - 한 번에 한 프로세스만 공유 자원 사용 가능
2. 점유대기(Hold and Wait)
   - 공유 자원에 대한 접근 권한을 가지고 있는 프로세스가, 그 권한을 release하지 않은 채 다른 자원에 대한 접근 권한을 요구할 수 있음
3. 비선점(No Preemption)
   - 한 프로세스가 다른 프로세스의 자원 접근 권한을 강제로 취소할 수 없음
4. 순환대기(Circular Wait)
   - 두 개 이상의 프로세스가 자원 접근을 기다리는데, 그 관계에 사이클 존재



#### 교착상태 처리

1. ##### 예방

   - 상호배제 부정 : 여러 프로세스가 공유 자원을 사용
   - 점유대기 부정 : 프로세스 실행 전에 모든 자원을 할당
   - 비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납
   - 순환대기 부정 : 자원에 고유번호 할당 후 순차대로 자원 요구

   

2. ##### 회피

   - 은행원 알고리즘

     > - 은행은 최소한 고객 한명에게 대출해줄 금액을 항상 보유하고 있어야 한다(안정 상태 추구)
     > - 시스템은 자원을 할당한 후에도 안정상태인지 사전에 검사
     > - 안정 상태면 자원을 할당, 불안정 상태면 다른 프로세스들의 자원 해지까지 대기
     >   - 안정 상태 : 시스템이 교착상태를 일으키지 않으며 최소 1개의 프로세스가 원하는 최대 요구량 만큼 줄 수 있는 상태
     >   - 불안정 상태 : 프로세스의 자원 할당 및 해제의 절차가 불명확하여 교착상태 발생 가능성이 농후한 상태

   

3. ##### 탐지 & 회복

   - 교착 상태가 되도록 허용한 다음 회복시키는 방법

     1. 탐지

        - 자원 할당 그래프를 통해 교착 상태 탐지
        - 자원 요청 시, 탐지 알고리즘을 수행시킴 => 오버헤드 발생

     2. 회복

        - 교착 상태 일으킨 프로세스를 종료 or 할당된 자원을 해제시켜 회복

          > 프로세스 종료 방법
          >
          > - 교착 상태의 프로세스 모두 중지
          > - 교착 상태 제거 될때까지 프로세스 하나씩 종료
          >
          >
          > 자원 선정 방법
          >
          > - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에게 할당(자원 뺏긴 프로세스는 일시중지)
          > - 우선 순위가 낮거나 실행 빈도수가 낮은 프로세스 위주로 자원 선점해버린다



#### 식사하는 철학자 문제

- 문제점
  - 상호배제 : 젓가락은 한번에 한 철학자만 사용 가능
  - 점유대기 : 집어든 젓가락을 계속 집은채로 반대편 젓가락 대기
  - 비선점 : 이미 할당된 젓가락을 뺏을 수 없음
  - 순환대기 : 모든 철학자들이 자신의 오른쪽 방향의 철학자가 젓가락을 놓기를 대기
- 해결 방법
  - N명이 앉을 수 있는 테이블에 N-1명 앉힌다(최소 한명은 할당할 수 있게끔 한다는 취지에서 은행원 알고리즘 적용)
  - 두개의 젓가락을 모두 집을 수 있는 상태에서만 젓가락 집기 허용(점유대기 부정)
  - 누군가는 왼쪽 젓가락을 먼저 집지 않고 오른쪽 젓가락을 먼저 집도록 허용(순환대기 부정)



## CPU Scheduling

> 메모리에 올라온 프로세스들 중 어떤 프로세스를 먼저 처리할지 일들의 순서를 정하는 일

효율성 ⇒ CPU 사용률,처리율 ↑/ 반환시간, 대기시간, 반응시간 ↓ 
공평성 ⇒ 각 기준에 있어 최적의 평균값과 이들 간의 편차를 최소화 
대화형 시스템 ⇒ 반응시간의 편차가 적은 스케줄러 선정



#### **장기 스케줄러(long term scheduler, 또는 작업 스케줄러)**

`메모리와 디스크 사이의 스케줄링`

- 스케줄러 원칙에 따라 디스크 내의 작업을 어떤 순서로 메모리에 가져올지 결정
- 디스크와 같은 저장장치에 작업들을 저장해 놓고, 필요할떄 실행할 작업을 ready Queue에서 꺼내 메모리에 적재
- New → Ready/ Running(or Ready) → Terminated



#### **단기 스케줄러(short term scheduler, 프로세스 스케줄러, CPU 스케줄러)**

`CPU와 메모리 사이의 스케줄링`

- 메모리에 있는 프로세스 중 하나를 선택해 프로세서를 할당
- Ready → Running → Waiting → Ready



#### 종류

##### 1. 비선점 스케줄링

`할당된 CPU를 다른 프로세스가 강제로 빼앗아 사용할 수 없는 스케줄링`

- CPU를 할당받은 프로세스가 종료되거나 입출력 조작을 위해 자발적으로 중지되기 전까지 CPU할당을 보장하는 스케줄링
  - **FIFO(=FCFS)**: 준비 큐에 도착한 순서로 CPU를 할당
  - **SJF(Short Job First)**: 준비 큐에 있는 프로세스들 중에 실행시간이 가장 짧은 프로세스에 CPU를 할당
  - **비선점 우선순위**: 각 프로세스에 우선순위를 부여하여 우선순위가 높은 순서대로 CPU를 할당
  - **HRRN(Highest Response Ratio Next)**: SJF의 기아 현상을 에이징기법으로 보완한 방법
    - 우선순위를 계산해서 [(대기시간 + 실행시간) / 실행시간] 우선순위별로 처리



##### 2. 선점 스케줄링

`우선순위가 높은 다른 프로세스가 CPU를 강제로 빼앗아 사용할 수 있는 스케줄링`

- 비선점 스케줄링의 경우 응답시간이 예상이 되는 장점이 존재하지만 중요하지 않은 일에 의해 중요한 일이 기다려야 하는 경우 발생

  - **RR(Round Robin)**: 시간 할당량 동안만 실행한 후 완료되지 않으면 다음 프로세스에서 CPU를 양보하고 Ready Queue의 맨 뒤에 배치

    ![](https://user-images.githubusercontent.com/55429912/120168491-e07aca00-c239-11eb-9d3b-baf34ace5970.png)

    - TQ(Time-Quantum, 시간 할당)이 클수록 FIFO와 유사, 작을 수록 Context Switching이 잦아짐에 따라서 오버헤드 발생
      

  - **SRT(Shortest Remaining Time)**: 최단 잔여시간을 우선으로 하는 스케줄링

  - **선점 우선순위**: 우선순위가 높은 순서대로 CPU를 할당, 준비 큐에 새로 들어온 프로세스의 우선순위가 현재 프로세스보다 높을 경우 CPU를 새로운 프로세스에게 할당

  - **MLQ(MultiLevel Queue, 다단계 큐)**: 커널 내의 준비 큐를 여러개의 큐로 분리하여 큐 사이에도 우선순위를 부여하는 스케줄링 알고리즘

    ![](https://user-images.githubusercontent.com/55429912/120174111-b1ffed80-c23f-11eb-9724-e80b05336d08.png)

    - 정적 우선순위를 사용하는 스케줄링을 구현할 때 가장 적합한 자료구조
    - 우선순위마다 준비 큐 생성(우선순위의 크기만큼 준비큐 필요)
    - 항상 가장 높은 우선순위 큐의 프로세스에 CPU를 할당(우선순위가 낮은 큐에서 작업이 실행중이더라도 상위 단계의 큐에 프로세스가 도착하면 CPU를 뺏기는 선점 방식)
    - 각 큐는 독자적 스케줄링 사용 가능
    - 큐들 간의 프로세스 이동이 불가능
    - 기아현상 발생할 수 있음

    

  - **MFQ(MultiLevel FeedBack Queue, 다단계 피드백 큐)**: 다단계 큐에서 피드백이 추가된 스케줄링

    ![](https://user-images.githubusercontent.com/55429912/120177565-87b02f00-c243-11eb-9379-6167a43d6fd4.png)

    - CPU Burst와 중요도의 상관관계

      `CPU Burst? 프로그램의 수행중에 연속적으로 CPU를 사용하는 단절된 구간, 스케줄링의 단위가 된다`

      - 만약 CPU Burst가 10초라면 이 프로세스의 어떤 특정 작업이 완료되기 위해서는 10초 동안 이 프로세스를 작업해줘야 한다는 것

    - MFQ는 우선순위가 높은 프로세스에게는 불이익을, 우선순위가 낮은 프로세스에게는 이익을 제공

    - 가장 우선순위가 낮은 큐를 제외하고는 모두 RR스케줄링 사용

      - 가장 낮은애는 보통 FCFS, RR사용

    - 우선순위가 높은 큐일 수 높은 TQ

      - 만약 해당 TQ동안 작업 처리되지 못했다면 우선순위가 낮다고 생각되어 그 아래 큐로 이동
      - 반대로 어떤 큐에서 일정시간동안 실행되지 못하고 있을 경우 우선순위 높은 큐로 이동

    - 기아현상을 `에이징 기법`으로 예방하였다

      > 에이징 기법?
      >
      > - 시스템에서 특정 프로세스의 우선순위가 낮아서 무한정 대기(기아)가 발생하는 경우를 방지하기 위해 기다린 시간에 비례해서 일정 시간이 지나면 우선순위를 한 단계씩 높여주는 방법
      > - 무한연기 or 기아상태를 예방하기 위함
      >   - SJF(Shortest-Job-First) => HRRN
      >   - MLQ => MFQ

  

  - **MLQ와 MFQ의 차이점**
    - 큐와 큐 사이에 프로세스들의 이동가능 여부
      - MLQ : 불가능, 스케줄링 부담이 적지만 유연성은 떨어짐
      - MFQ : 가능
    - 기아현상
      - MLQ : 하위 단계의 큐에 있을수록 CPU 할당을 받지 못하여 기아현상이 발생할 수 있음
      - MFQ : MLQ에 에이징 기법을 도입하여 기아 현상 예방 가능
    - Response Time
      - MLQ : 우선순위에 따라 다름
      - MFQ : interactive한 process(즉 CPU Burst가 적은 프로세스)가 높은 우선순위를 갖게 되어 Response Time이 짧음



## 페이징과 세그멘테이션

> `페이징 : 프로세스를 일정 크기인 페이지로 잘라서 메모리에 적재하는 방식`
>
> `세그멘테이션 : 논리적으로 독립된 의미의 세그먼트 단위(가변 단위)로 동작하는 메모리 관리 기법`



#### **가상 메모리란?**

`각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식`

- 멀티테스킹 운영체제에서 흔히 사용되며, 실제 주기억장치(RAM)보다 큰 영역을 제공하는 방법으로 사용



#### **가상 메모리 사용하는 이유?**

`다중 프로그래밍 시스템에 여러 프로세스를 수용하기 위해 주기억장치를 정적/동적 분할하는 메모리 관리 작업이 필요하기 때문 `



#### **메모리 관리 기법**

1. **연속 메모리 관리(a.k.a 연속 할당 기법)**

   `프로그램 전체가 하나의 커다란 공간에 연속적으로 할당됨`

   - 고정 분할 기법: 주기억장치가 고정된 파티션으로 분할(내부 단편화 발생)

     ![](https://user-images.githubusercontent.com/55429912/120224636-c7e0d300-c27e-11eb-8d78-12db7b1978d6.jpg)

   - 동적 분할 기법: 파티션들이 동적으로 생성되며 자신의 크기와 동일한 파티션에 적재(외부 단편화 발생)

     ![](https://user-images.githubusercontent.com/55429912/120224697-e3e47480-c27e-11eb-850e-752dca6888a1.jpg)

2. ##### **불연속 메모리 관리(a.k.a 불연속 할당 기법)**

   `프로그램의 일부가 서로 다른 주소 공간에 할당될 수 있는 기법`

   - 페이지: 고정 사이즈의 작은 프로세스 조각(프로세스를 나눈 조각)
   - 프레임: 고정 사이즈의 작은 주기억장치 조각(메모리를 나눈 조각)
   - 단편화: 기억 장치의 빈 공간 or 자료가 여러 조각으로 나뉘는 현상
   - 세그먼트: 서로 다른 크기를 가진 논리적 블록이 연속적 공간에 배치되는 것
     

**고정 크기 : 페이징**

**가변 크기 : 세그멘테이션**

- 단순 페이징
  - 각 프로세스는 프레임과 같은 크기를 가진 균등 페이지로 나뉨
  - 외부 단편화 X
  - 소량의 내부 단편화 존재
- 단순 세그멘테이션
  - 각 프로세스는 여러 세그먼트들로 나뉨
  - 내부 단편화 X, 메모리 사용 효율 개선, 동적 분할을 통한 오버헤드 감소
  - 외부 단편화 존재
- 가상 메모리 페이징
  - 단순 페이징과 비교해 프로세스 페이지 전부를 로드시킬 필요 X
  - 필요한 페이지가 있으면 나중에 자동으로 불러들어짐
  - 외부 단편화 X
  - Page Mapping이 필요하기에 오버헤드 발생
- 가상 메모리 세그멘테이션
  - 필요하지 않은 세그먼트들은 로드되지 않음
  - 필요한 세그먼트들이 있을때 나중에 자동으로 불러들어짐
  - 내부 단편화 X
  - 페이징과 동일하게 Page Mapping이 필요하기에 오버헤드 발생



#### **요구 페이징(Demand Paging)**

- 가상 메모리는 요구 페이징 기법을 통해 **필요한 페이지만 메모리에 적재**하고 사용하지 않는 부분은 그대로 둔다.
- 특정 페이지에 대해 CPU의 요청이 들어온 후에야 해당 페이지를 메모리에 적재하며, 한번도 접근되지 않은 페이지는 물리적 메모리에 적재되지 않는다.
- 이를 통해 메모리 사용량이 감소하고 프로세스 전체를 메모리에 올리는데 들었던 입출력 오버헤드가 감소하며 응답시간이 단축된다.
- 비트를 두어 각 페이지가 메모리에 존재하는지 표시
  - 유효 비트 : 페이지가 메모리에 적재됨
  - 무효 비트 : 페이지가 현재 메모리에 없거나, 그 페이지가 속한 주소 영역을 프로세스가 사용하지 않고 있는 경우
- CPU가 참조하려는 페이지가 현재 메모리에 적재되어있지 않은(무효 비트) 경우를 **Page Fault**라고 한다



#### Page Reference String?

![](https://user-images.githubusercontent.com/55429912/120226399-180d6480-c282-11eb-8c43-1e52f622e75f.jpg)

- CPU의 주소 요구에 따라 `Page Fault`가 일어나지 않는 부분은 생략하여 표시하는 방법



#### 페이지 교체 알고리즘

> 필요한 페이지만 메모리에 적재해도 결국 메모리는 가득참, 결국 메모리에 올라와있는 페이지중에 어떤 페이지를 OUT시키고 필요한 애를 넣을지를 정하는 알고리즘
>
> (이때 OUT되는 페이지를 Victim Page라고 한다)

##### 1. FIFO

- 메모리에 먼저 올라온 페이지를 먼저 내보냄
- 초기화 코드에 적합



##### 2. OPT

- 앞으로 가장 사용하지 않을 페이지를 우선적으로 내보내는 알고리즘
- 실질적으로 페이지가 앞으로 잘 사용되지 않을지 예측 불가능하기에 실질적으로 수행하기 어려움



##### 3. LRU(Least-Recently-Used)

- 최근에 사용하지 않은 페이지를 먼저 내보내는 알고리즘
- 과거 사용 내용을 기반으로 판단하므로 실질적인 알고리즘
- 교체 방식
  - Global 교체 : 메모리 상의 모든 프로세스 페이지에 대해 교체
  - Local 교체 : 메모리 상의 자신 프로세스 페이지에 대해서만 교체

- LRU 캐시 구현 방식
  - Doubly-Linked List와 HashMap을 사용
  - head에 가장 최근에 참조된 데이터를 저장
  - tail에는 가장 최근에 참조되지 않은 데이터를 저장
  - 교체가 일어나는 시점에 tail에 있는 데이터는 삭제 -> tail이 가장 오랫동안 사용되지 않은 데이터라서
  - 캐시에 존재하는지 아닌지, 실제 데이터를 불러오는데 hashMap을 이용해 O(1)로 찾아낸다
  - 삭제의 경우에는 이중 포인터를 이용함으로써 O(1)로 처리

## 메모리

#### 메인 메모리

> CPU가 직접 접근할 수 있는 접근 장치, 프로세스가 실행되려면 프로그램이 올라가야하는 위치



#### MMU(Memory Management Unit)

![](https://user-images.githubusercontent.com/55429912/120228354-e39ba780-c285-11eb-8ea9-d6e774f3a7d1.png)

- CPU 코어 안에 탑재되어 가상 주소를 실제 메모리 주소로 변환해주는 장치

- 메모리의 크기는 한정적이기에 더 많은 프로세스를 메모리에 적재하여 CPU 사용률을 높히기 위해 가상 주소라는 개념이 등장



#### 가상 주소

- 가상 메모리 기법으로 제공되는 주소 공간, 프로세스의 관점에서 사용하는 주소



#### MMU의 메모리 보호

프로세스는 독립적인 메모리 공간을 가져야하며, 자신의 공간만 접근 가능

따라서 한 프로세스에게 합법적 주소 영역 설정, 잘못된 접근이 오면 Trap(CPU가 자기 자신에게 인터럽트 거는 것)을 발생시키며 보호

![](https://user-images.githubusercontent.com/55429912/120228669-8bb17080-c286-11eb-8a69-9bbe84c20067.png)

- `base`와 `limit` 레지스터를 활용한 메모리 보호 기법

  - base 레지스터 : 메모리상의 프로세스의 시작 주소를 물리 주소로 저장
    - 프로세스가 합법적으로 접근할 수 있는 메모리 상의 가장 주소. 즉, 시작 주소를 의미
  - limit 레지스터 : 프로세스의 사이즈를 저장
    - 프로세스가 base 레지스터 값으로부터 접근할 수 있는 메모리의 범위를 보유

  즉, `base <= process access < base + limit`

  이 범위를 넘어가면 예외 상황이라는 **소프트웨어적 인터럽트 발생**(Trap 발생)

  사용자 모드인 경우 base, limit레지스터를 이용해 메모리를 보호

  커널 모드에서는 메모리에 무제한 접근 가능

  

  메모리 접근 명령은 특권 명령이 아님. **But 올바르지 않은 접근으로부터 메모리를 보호하기 위해**서는 `base register`와 `limit register`의 값을 세팅하는 연산은 `특권 명령`으로 규정해야함



#### 메모리 할당 알고리즘

1. First-Fit : 메모리를 처음부터 검사하여 가장 첫번째로 사용 가능한 공간에 할당
   - 빠른 메모리 할당 가능
   - 공간 활용률 저하
2. Best-Fit : 메모리 공간중 프로세스가 들어갈 수 있는 가장 딱 맞는 공간에 할당
   - 공간 활용률 높아짐
   - 메모리가 크기순으로 정렬되어있지 않다면 공간 검색시간이 늘어난다
3. Next-fit : 메모리 공간중 가장 큰 곳에 할당
   - 큰 메모리에 바로 할당하므로 검색이 빠름
   - 사용 가능한 메모리에 대한 정렬이 필요함, 공간 활용률이 떨어짐



#### 메모리 과할당(Over Allocating)

`실제 메모리 사이즈보다 더 큰 사이즈의 메모리를 프로세스에게 할당한 것`

페이징 기법과 같은 메모리 관리 기법은 사용자가 모르는 방식으로 메모리를 할당(가상 메모리 이용)

과할당 시에 이런 사용자가 모르는 방식이 들키는 상황 존재

1. 프로세스 실행 중에 Page Fault 발생
2. Page Fault를 발생시킨 페이지 위치를 디스크에서 찾음
3. 메모리의 빈 프레임에 페이지를 올려야 하는데, 모든 메모리가 사용중이라 빈 프레임이 없음



이런 과할당을 해결하기 위한 빈 프레임 확보하는 두 가지 방법 존재

1. 메모리에 적재되어있는 한 프로세스를 종료
2. 프로세스 하나를 swap out하고, 빈 프레임을 활용



swapping 기법을 통해 공간을 바꿔치기하는 2번의 방법과는 다르게 1번의 방법은 페이징 시스템을 들킬 가능성이 큼

즉, 2번 방식을 통해 페이지 교체가 이루어져야 한다



#### 페이지 교체

> 메모리 과할당 발생 시, 프로세스 하나를 swap out하여 빈 프레임 확보하는 것

위의 1~3 시나리오 발생

4. victim page를 선정, 디스크에 변경 사항을 기록, 페이지 테이블을 업데이트
5. 빈 프레임에 페이지 폴트가 발생한 페이지를 올리고, 페이지 테이블을 업데이트

페이지 교체가 이루어지면 사용자는 이 사실을 몰라야함. 즉, 프로세스는 계속 수행되어야함

이때 사용자가 모르게 하려면 페이지 교체(4~5)시에 오버헤드를 최대한 줄여야함

빈프레임이 없을 경우 `victim page를 스왑으로 넣을때`와 `원하는 페이지를 빈 프레임으로 넣을 때`두번의 디스크 접근이 이루어짐.. + 페이지 테이블 업데이트

##### 	오버헤드를 줄이는 방법

1. 변경 비트를 모든 페이지에 설정하여 victim page가 정해지면 해당 페이지의 변경 비트를 확인

   - 변경 비트가 set이면 해당 페이지 내용이 디스크 상의 내용과 달라졌다는 뜻(페이지가 메모리에 적재된 이후 수정이 일어났다는 것. 즉, 페이지 테이블(디스크)에 기록해야함)
   - 변경 비트가 clear이면 디스크 상의 페이지 내용과 메모리 상의 내용이 일치한다는 것(디스크에 기록 x)

   `변경 비트를 이용해서 디스크에 기록하는 횟수를 줄여 오버헤드를 감소시키는 방법`

2. 페이지 교체 알고리즘을 상황에 따라 선택
   - 현재 상황에서 페이지 폴트를 최대한 줄일 수 있는 교체 알고리즘 선택
     - FIFO, OPT, LRU



#### 캐시 메모리

> 주기억장치에 저장된 내용의 일부를 임시로 저장하는 기억장치
>
> CPU와 주기억장치의 속도 차이로 생기는 성능의 저하를 방지하기 위함

CPU가 이미 봤던 걸 재접근할 때, 메모리 참조 및 인출 과정에 대한 비용을 줄이기 위해 캐시에 저장된 데이터를 활용

캐시는 flip-flop소자로 구성되어 SRAM이기에 DRAM보다 빠름



##### 지역성의 원리

`캐시의 적중률을 극대화시키기 위해 사용하는 것`

- 시간 지역성 : 최근에 참조된 내용은 가까운 미래에 또 참조된다는 특성
- 공간 지역성 : 최근에 참조된 주소와 인접한 주소의 내용은 다시 참조된다는 특성



##### 캐시 미스

1. Compulsory Miss(=Cold Miss)
   - 최초 캐시 메모리가 초기화된 상태에서 발생되는 Miss
   - 지역성을 이용해서 미리 가져오는 방식으로 해결
2. Capacity Miss
   - 전체적인 용량 부족으로 인한 Miss
   - 용량을 늘려서 해결
3. Conflict Miss
   - Direct나 Set Associate Mapping에서 발생, 캐시 메모리에 A 데이터와  B 데이터에 같은 캐시 메모리 주소가 할당되어 일어나는 문제
   - 캐시 용량과는 상관 X
   - Fully Associate Mapping을 통해 해결



##### 캐시 구조

1. Direct Mapping(직접 사상)

   `주기억장치의 블록들이 지정된 한 개의 캐시 라인으로만 사상될 수 있는 매핑 방법`

   ![](https://user-images.githubusercontent.com/55429912/120374600-b833be00-c354-11eb-9ad1-6ea059215437.png)

   - 간단하고 구현하는 비용이 적게 든다
   - 적중률이 낮아질 수 있음



2. Fully Associative Mapping

   `비어있는 캐시메모리가 있으면, 마음대로 주소를 저장하는 방식`

   - 규칙이나 조건이 없어서 특정 캐시 Set내의 모든 블럭을 한번에 찾아 원하는 데이터가 있는지 검사
   - CAM(Content Addressable Memory)라는 특수 형태의 메모리 구조를 사용하는데 복잡하고 비용이 높다



3. Set Associative Mapping

   `Direct + Associative를 섞은 방식, 특정 행을 지정해서 그 행 안의 어떤 열이든 비어있으면 저장하는 방식`

   - Direct에 비해서 검색은 오래 걸리지만 저장이 빠름
   - Associative에 비해 저장이 느린 대신 검색이 빠름



## 파일 시스템

> 컴퓨터에서 파일이나 자료를 쉽게 발견 및 접근할 수 있도록 보관 또는 조직하는 체계

- 파일 시스템은 일반적으로 크기가 일정한 블록들의 배열에 접근할 수 있는 자료 보관 장치 위에 생성됨
- 이러한 배열들을 조직함으로 파일이나 디렉토리를 만들며 어느 부분이 파일이고 어느 부분이 공백인지를 구분하기 위해 배열에 표시함



#### 접근 방법

##### 1. 순차 접근(Sequential Access)

`가장 간단한 접근 방법으로 대부분 연산은 read, write`

![](https://user-images.githubusercontent.com/55429912/120263097-0190f880-c2d6-11eb-9356-1f30d6d717ae.png)

- 현재 위치를 가리키는 포인터에서 시스템 콜이 발생할 경우 포인터를 앞으로 보내면서 read와 write를 진행
- 뒤로 돌아갈 땐 지정한 offest만큼 되감기를 해야한다
  

##### 2. 직접 접근(Direct Access)

`특별한 순서없이, 빠르게 레코드를 read, write 가능`

![](https://user-images.githubusercontent.com/55429912/120263591-f5f20180-c2d6-11eb-9600-eecebd6eb4e6.png)

- 현재 위치를 가리키는 cp변수만 유지하면 직접 접근 파일을 가지고 순차 파일 기능을 쉽게 구현 가능
- 무작위 파일 블록에 대한 임의 접근을 허용(순서의 제약이 없음)
- 대규모 정보를 접근할 때 유용(데이터베이스에 활용)



##### 3. 기타 접근

`직접 접근 파일에 기반하여 색인 구축`

![](https://user-images.githubusercontent.com/55429912/120264238-49b11a80-c2d8-11eb-8448-3320422c04fa.png)

- 크기가 큰 파일을 입출력 탐색할 수 있게 도와주는 방법



#### 디렉토리와 디스크 구조

- **1단계 디렉토리**

  ![](https://user-images.githubusercontent.com/55429912/120265093-34d58680-c2da-11eb-8410-d1da3d6ec7cd.png)
  - 파일들은 서로 유일한 이름을 가짐, 서로 다른 사용자라도 같은 이름 사용 불가



- **2단계 디렉토리**

  `사용자마다 개별적인 디렉토리`

  ![](https://user-images.githubusercontent.com/55429912/120265177-64848e80-c2da-11eb-9c81-b8779db723bd.png)

  - MFD(Master File Directory) : 사용자의 이름과 계정 번호로 색인되어 있는 디렉토리
  - UFD(User File Directory) : 자신만의 사용자 파일 디렉토리



- **트리 구조 디렉토리**

  `2단계 구조에서 확장된 다단계 트리 구조`

  ![](https://user-images.githubusercontent.com/55429912/120265329-bfb68100-c2da-11eb-9387-a2625e4636d8.png)

  - 한 비트를 활용하여, 일반 파일(0)인지 디렉토리 파일(1)인지 구분
  - 파일 또는 디렉토리의 공유를 허용하지 않음



- **비순환 그래프 디렉토리**

  `디렉토리들이 서브디렉토리들과 파일들을 공유할 수 있도록 허용하는 구조`

  ![](https://user-images.githubusercontent.com/55429912/120266555-250b7180-c2dd-11eb-84a3-3f16998d8770.png)

  - 디렉토리들이 서브 디렉토리들과 파일 공유 가능
  - 하나의 파일이나 디렉토리가 여러개의 경로 이름을 가질 수 있음
  - 링크는 다른 파일이나 서브 디렉토리를 가리키는 포인터를 가지고 참조
  - 공유 파일 삭제 시 존재하지 않는 파일을 가리키는 Dangling 포인터 생성됨
    - 참조계수를 사용하여 모든 참조가 지워질 때까지 원본 파일을 보존하게 하여 해결



- **일반 그래프 디렉토리**

  `트리 구조에 링크를 더해 순환을 허용하는 그래프 구조`

  ![](https://user-images.githubusercontent.com/55429912/120267401-d8c13100-c2de-11eb-8eae-fca6d516875e.png)

  - 사이클 허용
  - 불필요한 파일제거를 위해 참조카운터 필요

